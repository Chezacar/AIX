### 半监督生成式方法介绍

***

【**参考资料**】

周志华	《机器学习》

南瓜书	[半监督学习](<https://datawhalechina.github.io/pumpkin-book/#/chapter13/chapter13>)

李宏毅  机器学习课程   [半监督学习](<http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/semi%20(v3).pdf>)



半监督生成式方法假设所有样本独立同分布，标记样本和未标记样本都是由同一个生成模型生成的。以高斯混合模型为例，给定样本$x$，其真实类别标记$y \in \mathcal{Y}$，其中$\mathcal{Y}=\{1,2, \ldots, N\}$为所有可能的类别。假设样本由高斯混合模型生成，且每个类别对应一个高斯混合成分，即
$$
p(\boldsymbol{x})=\sum_{i=1}^{N} \alpha_{i} \cdot p\left(\boldsymbol{x} | \boldsymbol{\mu}_{i}, \mathbf{\Sigma}_{i}\right) \tag{1}
$$
其中，混合系数$\alpha_{i} \geqslant 0$，$\sum_{i=1}^{N} \alpha_{i}=1$；$p\left(\boldsymbol{x} | \boldsymbol{\mu}_{i}, \mathbf{\Sigma}_{i}\right)$是样本$x$属于第$i$个高斯混合成分的概率；$\mu_{i}$和$\boldsymbol{\Sigma}_{i}$为该高斯混合成分的参数。

现在给定标记样本集合$D_{l}=\left\{\left(\boldsymbol{x}_{1}, y_{1}\right),\left(\boldsymbol{x}_{2}, y_{2}\right), \ldots,\left(\boldsymbol{x}_{l}, y_{l}\right)\right\}$和未标记样本集合$D_{u}=\left\{\boldsymbol{x}_{l+1}, \boldsymbol{x}_{l+2}, \ldots, \boldsymbol{x}_{l+u}\right\}$，$l \ll u$，$l+u=m$，并且假设它们都是独立同分布的。用极大似然法来估计高斯混合模型的参数$\left\{\left(\alpha_{i}, \boldsymbol{\mu}_{i}, \mathbf{\Sigma}_{i}\right) | 1 \leqslant i \leqslant N\right\}$，$D_{l} \cup D_{u}$的对数似然是
$$
\begin{aligned} L L\left(D_{l} \cup D_{u}\right)=& \sum_{\left(x_{j}, y_{j}\right) \in D_{l}} \ln \left(\sum_{i=1}^{N} \alpha_{i} \cdot p\left(\boldsymbol{x}_{j} | \boldsymbol{\mu}_{i}, \mathbf{\Sigma}_{i}\right) \cdot p\left(y_{j} | \Theta=i, \boldsymbol{x}_{j}\right)\right) \\ &+\sum_{x_{j} \in D_{u}} \ln \left(\sum_{i=1}^{N} \alpha_{i} \cdot p\left(\boldsymbol{x}_{j} | \boldsymbol{\mu}_{i}, \mathbf{\Sigma}_{i}\right)\right) \end{aligned} \tag{2}
$$
式（2）中的第一项是有标记数据的特征和标签的联合概率分布$P(x,y)$，第二项是无标记数据特征的概率分布$P(x)$。

高斯混合模型的参数估计需要使用EM算法求解，迭代更新过程如下：

* E步：根据当前模型参数计算未标记样本$\boldsymbol{x}_{j}$属于各高斯混合成分的后验概率
  $$
  \gamma_{j i}=\frac{\alpha_{i} \cdot p\left(\boldsymbol{x}_{j} | \boldsymbol{\mu}_{i}, \boldsymbol{\Sigma}_{i}\right)}{\sum_{i=1}^{N} \alpha_{i} \cdot p\left(\boldsymbol{x}_{j} | \boldsymbol{\mu}_{i}, \boldsymbol{\Sigma}_{i}\right)} \tag{3}
  $$

* M步：基于$\gamma_{j i}$更新模型参数，其中$l_{i}$表示第$i$类的有标记样本数目
  $$
  \boldsymbol{\mu}_{i}=\frac{1}{\sum_{\boldsymbol{x}_{j} \in D_{u}} \gamma_{j i}+l_{i}}\left(\sum_{\boldsymbol{x}_{j} \in D_{\boldsymbol{u}}} \gamma_{j i} \boldsymbol{x}_{j}+\sum_{\left(\boldsymbol{x}_{j}, y_{j}\right) \in D_{l} \wedge y_{j}=i} \boldsymbol{x}_{j}\right) \tag{4}
  $$

  $$
  \begin{aligned} \boldsymbol{\Sigma}_{i}=& \frac{1}{\sum_{\boldsymbol{x}_{j} \in D_{u}} \gamma_{j i}+l_{i}}\left(\sum_{\boldsymbol{x}_{j} \in D_{u}} \gamma_{j i}\left(\boldsymbol{x}_{j}-\boldsymbol{\mu}_{i}\right)\left(\boldsymbol{x}_{j}-\boldsymbol{\mu}_{i}\right)^{\mathrm{T}}\right.\\  + & \left. \sum_{\left(\boldsymbol{x}_{j}, y_{j}\right) \in D_{l} \wedge y_{j}=i}\left(\boldsymbol{x}_{j}-\boldsymbol{\mu}_{i}\right)\left(\boldsymbol{x}_{j}-\boldsymbol{\mu}_{i}\right)^{\mathrm{T}} \right) \end{aligned}
  \tag{5}
  $$

  $$
  \alpha_{i}=\frac{1}{m}\left(\sum_{\boldsymbol{x}_{j} \in D_{u}} \gamma_{j i}+l_{i}\right) \tag{6}
  $$

参数更新的过程相当直观，实际上是用无标记样本对原来的、仅包含有标记样本的参数更新公式进行修正：

式（4）求均值$\mu$，括号内的第二项是对带标记的样本中，类别为$i$的样本特征$x_j$求和，即$\sum_{\left(x_{j}, y_{j}\right) \in D_{l} \wedge y_{j}=i} \boldsymbol{x}_{j}$，第一项则是无标记样本特征$x_j$的加权和，而权重就是无标记样本属于类别$i$的概率，即$\sum_{x_{i} \in D_{y}} \gamma_{j i} \boldsymbol{x}_{j}$。然后除以的是类别为$i$的有标记样本数目，加上无标记样本属于类别$i$的概率的和。

式（5）同理。

式（6）求解的$\alpha$即为类别的先验概率，类似地，用类别为$i$的有标记样本数目，加上无标记样本属于类别$i$的概率的和，去除以样本的总数$m$。

要求解后验概率，即式（3），可以通过有标记数据来对模型参数进行初始化，具体来说：
$$
\alpha_{i}=\frac{l_{i}}{\left|D_{l}\right|}, \text { where }\left|D_{l}\right|=\sum_{i=1}^{N} l_{i}\\
\mu_{i}=\frac{1}{l_{i}} \sum_{\left(x_{j}, y_{j}\right) \in D_{l} \wedge y_{i}=i}\left(x_{j}-\mu_{j}\right)\left(x_{j}-\mu_{j}\right)^{T}\\
\Sigma_{i}=\frac{1}{l_{i}} \sum_{\left(x_{j}, y_{j}\right) \in D l \wedge y j=i}\left(x_{j}-\mu_{i}\right)\left(x_{j}-\mu_{i}\right)^{\top}
$$
注意上面三个式子与在有无标记数据参与下的参数求解式（4）、（5）、（6）的对比。

详细的推导过程请见：

<https://datawhalechina.github.io/pumpkin-book/#/chapter13/chapter13>

如果使用其他生成模型来对数据分布进行建模，那么就会导出不同的半监督生成式方法。

半监督的生成式方法在**有标记数据极少**的情形下往往会比其他方法性能更好。然而，这类方法的关键在于，**模型假设必须准确**，即假设的生成模型必须与真实数据分布吻合，否则利用未标记数据反而会降低泛化性能。但是在实际中很难作出正确的模型假设，所以生成式方法具有很大的局限性。